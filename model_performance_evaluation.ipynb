{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5cbaa5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libaries\n",
    "\n",
    "# Standard libaries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns; sns.set()   \n",
    "import configparser\n",
    "import os\n",
    "from pathlib import Path\n",
    "import argparse\n",
    "import logging\n",
    "import datetime\n",
    "import inspect\n",
    "from sklearn.utils import resample\n",
    "import re\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "import plotly.express as px\n",
    "import plotly.graph_objs as go\n",
    "import math\n",
    "import pickle\n",
    "\n",
    "# Additional\n",
    "import matplotlib.dates as mdates\n",
    "import joblib\n",
    "import time # to claculate the runtime of models\n",
    "from pathlib import Path \n",
    "import pymannkendall as mk # Kendall tau trend package\n",
    "\n",
    "# Internal Packages\n",
    "from analyse_df import analyse_df\n",
    "from rename_columns import rename_columns\n",
    "import plot_settings\n",
    "from glob import glob\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "628d7e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the current directory\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "# Define the paths to the 'data' and 'export' directories\n",
    "data_path = os.path.join(current_dir, 'data')\n",
    "export_path = os.path.join(current_dir, 'export')\n",
    "\n",
    "# Define path of single-node-model files\n",
    "single_node_path = os.path.join(export_path, 'single_node', 'unscaled', '90_seconds_intervals')\n",
    "\n",
    "# Define path of network model files\n",
    "network_path = os.path.join(export_path, 'network')\n",
    "\n",
    "# Get a list of all CSV files in the single-node-model directory\n",
    "file_path_test_single_node = glob(os.path.join(single_node_path, 'df_test_elba_rocket_*'))\n",
    "\n",
    "# Get a list of all CSV files in the network model directory\n",
    "file_path_test_network = glob(os.path.join(network_path, 'df_test_elba_rocket_network*'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8d5802d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1761\n",
      "1761\n",
      "1761\n",
      "1761\n",
      "1761\n",
      "1761\n",
      "1761\n",
      "1761\n",
      "1761\n"
     ]
    }
   ],
   "source": [
    "# Import single-node files\n",
    "df_list = []\n",
    "list_sensornodes= []\n",
    "\n",
    "# Import data for single node model\n",
    "for file in file_path_test_single_node:\n",
    "    # Extract sensornode and scaler name from the filename\n",
    "    filename = os.path.splitext(os.path.basename(file))[0]\n",
    "    sensornode_name, scaler_name = filename.split('_')[-2:]\n",
    "    \n",
    "    # Read the CSV file into a DataFrame\n",
    "    df = pd.read_csv(file, index_col=0)\n",
    "    \n",
    "    # Keep only 'fire_label' and 'model_prediction' columns\n",
    "    df = df[['fire_label', 'model_prediction']]\n",
    "    \n",
    "    # Group by the index and aggregate by keeping the most frequent value in each group\n",
    "    df_grouped = df.groupby(df.index).agg(lambda x: x.mode()[0])\n",
    "    print(len(df_grouped))\n",
    "    \n",
    "    # Append the grouped DataFrame to the list\n",
    "    df_list.append(df_grouped)\n",
    "    \n",
    "    list_sensornodes.append(sensornode_name)\n",
    "\n",
    "# Concatenate all DataFrames in the list into a single DataFrame\n",
    "df_prediction_single_node_model = pd.concat(df_list, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c1df6ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1761\n"
     ]
    }
   ],
   "source": [
    "# Import network files\n",
    "df_list = []\n",
    "\n",
    "# Import data for single node model\n",
    "for file in file_path_test_network:\n",
    "    # Extract sensornode and scaler name from the filename\n",
    "    #filename = os.path.splitext(os.path.basename(file))[0]\n",
    "    #sensornode_name, scaler_name = filename.split('_')[-2:]\n",
    "    \n",
    "    # Read the CSV file into a DataFrame\n",
    "    df = pd.read_csv(file, index_col=0)\n",
    "    \n",
    "    # Keep only 'fire_label' and 'model_prediction' columns\n",
    "    df = df[['fire_label', 'model_prediction']]\n",
    "    \n",
    "    # Group by the index and aggregate by keeping the most frequent value in each group\n",
    "    df_grouped = df.groupby(df.index).agg(lambda x: x.mode()[0])\n",
    "    print(len(df_grouped))\n",
    "    \n",
    "    # Append the grouped DataFrame to the list\n",
    "    df_list.append(df_grouped)\n",
    "\n",
    "# Concatenate all DataFrames in the list into a single DataFrame\n",
    "df_prediction_network_model = pd.concat(df_list, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8160a6c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fire_label</th>\n",
       "      <th>model_prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NoFire</td>\n",
       "      <td>NoFire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NoFire</td>\n",
       "      <td>NoFire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NoFire</td>\n",
       "      <td>NoFire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NoFire</td>\n",
       "      <td>NoFire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NoFire</td>\n",
       "      <td>NoFire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1756</th>\n",
       "      <td>NoFire</td>\n",
       "      <td>NoFire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1757</th>\n",
       "      <td>NoFire</td>\n",
       "      <td>NoFire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1758</th>\n",
       "      <td>NoFire</td>\n",
       "      <td>NoFire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1759</th>\n",
       "      <td>NoFire</td>\n",
       "      <td>NoFire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1760</th>\n",
       "      <td>NoFire</td>\n",
       "      <td>NoFire</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1761 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     fire_label model_prediction\n",
       "0        NoFire           NoFire\n",
       "1        NoFire           NoFire\n",
       "2        NoFire           NoFire\n",
       "3        NoFire           NoFire\n",
       "4        NoFire           NoFire\n",
       "...         ...              ...\n",
       "1756     NoFire           NoFire\n",
       "1757     NoFire           NoFire\n",
       "1758     NoFire           NoFire\n",
       "1759     NoFire           NoFire\n",
       "1760     NoFire           NoFire\n",
       "\n",
       "[1761 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_prediction_network_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b17862",
   "metadata": {},
   "source": [
    "## Single node model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6883c926",
   "metadata": {},
   "outputs": [],
   "source": [
    "# derive confusion matrix for single node model (mean over all node positions)\n",
    "\n",
    "# Extract the ground truth and predictions\n",
    "y_true = df_prediction_single_node_model['fire_label']\n",
    "y_pred = df_prediction_single_node_model['model_prediction']\n",
    "\n",
    "# Generate the confusion matrix\n",
    "conf_matrix = confusion_matrix(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9fb24b49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lr}\n",
      "\\toprule\n",
      "              Metric &   Value \\\\\n",
      "\\midrule\n",
      " True Positives (TP) & 1645.11 \\\\\n",
      "False Positives (FP) &    2.44 \\\\\n",
      " True Negatives (TN) &   94.56 \\\\\n",
      "False Negatives (FN) &   18.89 \\\\\n",
      "                 FPR &    0.03 \\\\\n",
      "        Recall (TPR) &    0.99 \\\\\n",
      "     Precision (PPV) &    1.00 \\\\\n",
      "            F1-score &    0.99 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pascal\\AppData\\Local\\Temp\\ipykernel_17404\\1791288641.py:28: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  latex_table = metrics_df_single_node.to_latex(index=False, float_format=\"%.2f\")\n"
     ]
    }
   ],
   "source": [
    "# calculate scores for single-node-model\n",
    "# FPR, recall (TPR), precision (PPV), F1-score + confusion matrix fÃ¼r beide models (TP, FP, TN, FN)\n",
    "\n",
    "# Extract the values from the confusion matrix\n",
    "TN, FP, FN, TP = conf_matrix.ravel()\n",
    "\n",
    "# devide by the number of sensor nodes to get the counts for equal number of intervals then the network model\n",
    "# Divide the values by the defined number\n",
    "TN /= len(list_sensornodes)\n",
    "FP /= len(list_sensornodes)\n",
    "FN /= len(list_sensornodes)\n",
    "TP /= len(list_sensornodes)\n",
    "\n",
    "# Calculate metrics manually\n",
    "FPR = FP / (FP + TN)  # False Positive Rate\n",
    "TPR = TP / (TP + FN)  # True Positive Rate (Recall)\n",
    "PPV = TP / (TP + FP)  # Precision (Positive Predictive Value)\n",
    "F1 = 2 * PPV * TPR / (PPV + TPR)  # F1-score\n",
    "\n",
    "# Create a DataFrame to store the metrics\n",
    "metrics_df_single_node = pd.DataFrame({\n",
    "    'Metric': ['True Positives (TP)', 'False Positives (FP)', 'True Negatives (TN)', 'False Negatives (FN)', \n",
    "               'FPR', 'Recall (TPR)', 'Precision (PPV)', 'F1-score'],\n",
    "    'Value': [TP, FP, TN, FN, FPR, TPR, PPV, F1]\n",
    "})\n",
    "\n",
    "# Convert the DataFrame to a LaTeX table\n",
    "latex_table = metrics_df_single_node.to_latex(index=False, float_format=\"%.2f\")\n",
    "print(latex_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c0e1752",
   "metadata": {},
   "source": [
    "## Network model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7795dd47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# derive confusion matrix for network model\n",
    "\n",
    "# Extract the ground truth and predictions\n",
    "y_true = df_prediction_network_model['fire_label']\n",
    "y_pred = df_prediction_network_model['model_prediction']\n",
    "\n",
    "# Generate the confusion matrix\n",
    "conf_matrix = confusion_matrix(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5ccd8bfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lr}\n",
      "\\toprule\n",
      "              Metric &   Value \\\\\n",
      "\\midrule\n",
      " True Positives (TP) & 1664.00 \\\\\n",
      "False Positives (FP) &    1.00 \\\\\n",
      " True Negatives (TN) &   96.00 \\\\\n",
      "False Negatives (FN) &    0.00 \\\\\n",
      "                 FPR &    0.01 \\\\\n",
      "        Recall (TPR) &    1.00 \\\\\n",
      "     Precision (PPV) &    1.00 \\\\\n",
      "            F1-score &    1.00 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pascal\\AppData\\Local\\Temp\\ipykernel_17404\\2100440992.py:21: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  latex_table = metrics_df_network.to_latex(index=False, float_format=\"%.2f\")\n"
     ]
    }
   ],
   "source": [
    "# calculate scores for network model\n",
    "# FPR, recall (TPR), precision (PPV), F1-score + confusion matrix fÃ¼r beide models (TP, FP, TN, FN)\n",
    "\n",
    "# Extract the values from the confusion matrix\n",
    "TN, FP, FN, TP = conf_matrix.ravel()\n",
    "\n",
    "# Calculate metrics manually\n",
    "FPR = FP / (FP + TN)  # False Positive Rate\n",
    "TPR = TP / (TP + FN)  # True Positive Rate (Recall)\n",
    "PPV = TP / (TP + FP)  # Precision (Positive Predictive Value)\n",
    "F1 = 2 * PPV * TPR / (PPV + TPR)  # F1-score\n",
    "\n",
    "# Create a DataFrame to store the metrics\n",
    "metrics_df_network = pd.DataFrame({\n",
    "    'Metric': ['True Positives (TP)', 'False Positives (FP)', 'True Negatives (TN)', 'False Negatives (FN)', \n",
    "               'FPR', 'Recall (TPR)', 'Precision (PPV)', 'F1-score'],\n",
    "    'Value': [TP, FP, TN, FN, FPR, TPR, PPV, F1]\n",
    "})\n",
    "\n",
    "# Convert the DataFrame to a LaTeX table\n",
    "latex_table = metrics_df_network.to_latex(index=False, float_format=\"%.2f\")\n",
    "print(latex_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d95c0728",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eb164224",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrr}\n",
      "\\toprule\n",
      "{} &  Network Model &  Single Node Model \\\\\n",
      "Metric               &                &                    \\\\\n",
      "\\midrule\n",
      "True Positives (TP)  &        1664.00 &            1645.11 \\\\\n",
      "False Positives (FP) &           1.00 &               2.44 \\\\\n",
      "True Negatives (TN)  &          96.00 &              94.56 \\\\\n",
      "False Negatives (FN) &           0.00 &              18.89 \\\\\n",
      "FPR                  &           0.01 &               0.03 \\\\\n",
      "Recall (TPR)         &           1.00 &               0.99 \\\\\n",
      "Precision (PPV)      &           1.00 &               1.00 \\\\\n",
      "F1-score             &           1.00 &               0.99 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pascal\\AppData\\Local\\Temp\\ipykernel_17404\\3085552194.py:10: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  latex_table = metrics_df_combined.to_latex(index=True, float_format=\"%.2f\")\n"
     ]
    }
   ],
   "source": [
    "# Set 'Metric' as index for both DataFrames\n",
    "metrics_df_network.set_index('Metric', inplace=True)\n",
    "metrics_df_single_node.set_index('Metric', inplace=True)\n",
    "\n",
    "# Combine the DataFrames side by side\n",
    "metrics_df_combined = pd.concat([metrics_df_network, metrics_df_single_node], axis=1)\n",
    "metrics_df_combined.columns = ['Network Model', 'Single Node Model']\n",
    "\n",
    "# Optionally, format the DataFrame for LaTeX output\n",
    "latex_table = metrics_df_combined.to_latex(index=True, float_format=\"%.2f\")\n",
    "\n",
    "# Print the LaTeX table\n",
    "print(latex_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4adc1c3b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
